# ğŸ¤– AI Search & Aggregation Service - Implementation Plan

## ğŸ“‹ **Service Overview**

**Purpose:** Provide intelligent product search, recommendations, and aggregated analytics using AI/ML capabilities.

**Port:** 8004

**Key Features:**
- Semantic search (vector embeddings)
- Product recommendations (collaborative & content-based)
- Search analytics
- Trending products detection
- Personalized search results
- Query understanding & expansion

---

## ğŸ“‚ **Folder Structure**

```
services/ai-search-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py                     # Configuration (API keys, model paths)
â”‚   â”‚
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ search_query.py            # SearchQuery, SearchResult models
â”‚   â”‚   â”‚   â”œâ”€â”€ product_embedding.py       # ProductEmbedding model
â”‚   â”‚   â”‚   â””â”€â”€ recommendation.py          # UserRecommendation model
â”‚   â”‚   â””â”€â”€ interfaces/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ embedding_interface.py     # Abstract embedding provider
â”‚   â”‚
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ search_service.py          # Main search logic
â”‚   â”‚   â”‚   â”œâ”€â”€ recommendation_service.py  # Recommendation engine
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics_service.py       # Search analytics
â”‚   â”‚   â”‚   â””â”€â”€ embedding_service.py       # Vector embedding generation
â”‚   â”‚   â””â”€â”€ dtos/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ search_schemas.py          # Search request/response DTOs
â”‚   â”‚       â”œâ”€â”€ recommendation_schemas.py  # Recommendation DTOs
â”‚   â”‚       â””â”€â”€ analytics_schemas.py       # Analytics DTOs
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py              # PostgreSQL connection
â”‚   â”‚   â”‚   â”œâ”€â”€ search_repository.py       # Search queries storage
â”‚   â”‚   â”‚   â””â”€â”€ embedding_repository.py    # Vector storage
â”‚   â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pinecone_client.py         # Pinecone vector DB (optional)
â”‚   â”‚   â”‚   â””â”€â”€ pgvector_client.py         # PostgreSQL pgvector extension
â”‚   â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ sentence_transformer.py    # Sentence embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ recommendation_model.py    # ML recommendation logic
â”‚   â”‚   â”‚   â””â”€â”€ query_processor.py         # NLP query processing
â”‚   â”‚   â””â”€â”€ external/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ product_client.py          # Product Service API client
â”‚   â”‚       â””â”€â”€ analytics_client.py        # Analytics Service client
â”‚   â”‚
â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ search_routes.py           # Search endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ recommendation_routes.py   # Recommendation endpoints
â”‚   â”‚   â”‚   â””â”€â”€ analytics_routes.py        # Analytics endpoints
â”‚   â”‚   â””â”€â”€ middlewares/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ auth_middleware.py         # JWT validation
â”‚   â”‚       â””â”€â”€ rate_limit.py              # Rate limiting
â”‚   â”‚
â”‚   â””â”€â”€ main.py                             # FastAPI application
â”‚
â”œâ”€â”€ ml_models/                              # Pre-trained ML models
â”‚   â”œâ”€â”€ sentence_transformer/               # Embedding model
â”‚   â””â”€â”€ recommendation/                     # Recommendation model weights
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_embeddings.py             # Batch generate embeddings
â”‚   â”œâ”€â”€ train_recommendations.py           # Train recommendation model
â”‚   â””â”€â”€ migrate_vectors.py                 # Vector DB migration
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_search_service.py
â”‚   â”‚   â”œâ”€â”€ test_embedding_service.py
â”‚   â”‚   â””â”€â”€ test_recommendation_service.py
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_search_api.py
â”‚
â”œâ”€â”€ requirements.txt                        # Python dependencies
â”œâ”€â”€ Dockerfile                              # Container definition
â”œâ”€â”€ .env.example                            # Environment template
â””â”€â”€ README.md                               # Documentation
```

---

## ğŸ¯ **Core Features to Implement**

### **1. Semantic Search**
- Vector embeddings for products (title, description)
- Similarity search using cosine distance
- Query expansion (synonyms, related terms)
- Fuzzy matching for typos
- Multi-field search (category, metadata)

### **2. Product Recommendations**
- **Collaborative Filtering:** Users who bought X also bought Y
- **Content-Based:** Similar products based on attributes
- **Hybrid:** Combine both approaches
- Personalized recommendations based on user history

### **3. Search Analytics**
- Track search queries
- Popular search terms
- Failed searches (no results)
- Search-to-purchase conversion
- Trending searches

### **4. AI-Powered Features**
- Query intent detection
- Auto-complete suggestions
- Search result ranking
- Personalized search results
- Visual similarity (if images)

---

## ğŸ—„ï¸ **Database Schema**

### **search_queries** (PostgreSQL)
```sql
CREATE TABLE search_queries (
    id UUID PRIMARY KEY,
    user_id UUID,                    -- NULL if anonymous
    query TEXT NOT NULL,
    results_count INTEGER,
    clicked_product_id UUID,         -- Which product was clicked
    converted BOOLEAN DEFAULT FALSE, -- Did it lead to purchase
    timestamp TIMESTAMP DEFAULT NOW(),
    metadata JSONB                   -- Additional data
);

CREATE INDEX idx_search_queries_user ON search_queries(user_id);
CREATE INDEX idx_search_queries_timestamp ON search_queries(timestamp);
```

### **product_embeddings** (PostgreSQL with pgvector)
```sql
CREATE EXTENSION vector;

CREATE TABLE product_embeddings (
    id UUID PRIMARY KEY,
    product_id UUID NOT NULL UNIQUE,
    embedding vector(384),            -- 384-dim from sentence-transformers
    last_updated TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_product_embeddings_vector 
ON product_embeddings USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

### **user_recommendations** (PostgreSQL)
```sql
CREATE TABLE user_recommendations (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL,
    recommended_product_id UUID NOT NULL,
    score FLOAT,                      -- Recommendation confidence
    reason VARCHAR(50),               -- 'similar', 'bought_together', 'trending'
    created_at TIMESTAMP DEFAULT NOW(),
    shown BOOLEAN DEFAULT FALSE,      -- Was it shown to user
    clicked BOOLEAN DEFAULT FALSE     -- Did user click it
);

CREATE INDEX idx_user_recs_user ON user_recommendations(user_id);
```

---

## ğŸ”§ **Technology Stack**

### **Core:**
- **FastAPI** - Web framework
- **PostgreSQL** - Main database
- **pgvector** - Vector similarity search extension
- **Redis** - Caching search results

### **ML/AI Libraries:**
- **sentence-transformers** - Text embeddings (384-dim)
- **scikit-learn** - Recommendation algorithms
- **numpy** - Vector operations
- **pandas** - Data manipulation

### **Optional Advanced:**
- **Pinecone** - Managed vector database
- **OpenAI API** - GPT for query understanding
- **Hugging Face** - Pre-trained models
- **Elasticsearch** - Full-text search (alternative)

---

## ğŸš€ **Implementation Plan**

### **Phase 1: Foundation (Week 1)**
1. âœ… Set up service structure
2. âœ… Configure FastAPI application
3. âœ… Set up PostgreSQL with pgvector
4. âœ… Create domain models
5. âœ… Implement basic repositories

### **Phase 2: Embedding System (Week 2)**
1. âœ… Integrate sentence-transformers
2. âœ… Create embedding generation script
3. âœ… Generate embeddings for existing products
4. âœ… Set up vector storage (pgvector)
5. âœ… Implement similarity search

### **Phase 3: Search Service (Week 3)**
1. âœ… Implement semantic search
2. âœ… Add query preprocessing (lowercase, stemming)
3. âœ… Implement hybrid search (vector + keyword)
4. âœ… Add search result ranking
5. âœ… Implement autocomplete
6. âœ… Create search analytics tracking

### **Phase 4: Recommendations (Week 4)**
1. âœ… Implement collaborative filtering
2. âœ… Implement content-based filtering
3. âœ… Create recommendation API endpoints
4. âœ… Add personalization logic
5. âœ… Implement "Similar Products"
6. âœ… Add "Frequently Bought Together"

### **Phase 5: Analytics & Optimization (Week 5)**
1. âœ… Create analytics dashboard endpoints
2. âœ… Implement trending products detection
3. âœ… Add search performance metrics
4. âœ… Optimize vector search queries
5. âœ… Add caching layer (Redis)
6. âœ… Performance testing

### **Phase 6: Advanced Features (Week 6)**
1. âœ… Query intent detection
2. âœ… Failed search handling
3. âœ… A/B testing support
4. âœ… Personalized ranking
5. âœ… Real-time index updates
6. âœ… Integration testing

---

## ğŸ“¡ **API Endpoints**

### **Search Endpoints:**
```
POST   /api/search/semantic          # Semantic search
POST   /api/search/autocomplete      # Auto-complete suggestions
GET    /api/search/trending          # Trending searches
GET    /api/search/history           # User search history
```

### **Recommendation Endpoints:**
```
GET    /api/recommendations/user/{user_id}           # Personalized
GET    /api/recommendations/product/{product_id}    # Similar products
GET    /api/recommendations/trending                # Trending products
POST   /api/recommendations/batch                   # Batch recommendations
```

### **Analytics Endpoints:**
```
GET    /api/analytics/search-stats          # Search statistics
GET    /api/analytics/popular-queries        # Popular searches
GET    /api/analytics/failed-searches        # Searches with no results
GET    /api/analytics/conversion             # Search-to-purchase rate
```

---

## ğŸ”— **External Service Integration**

### **Product Service Integration:**
```python
# Get product details for search results
GET /api/products/{id}
GET /api/products?ids={id1,id2,id3}  # Batch fetch

# Get all products for embedding generation
GET /api/products?page_size=1000
```

### **Analytics Service Integration:**
```python
# Send search events
POST /api/analytics/events
{
  "event_type": "product_search",
  "user_id": "...",
  "product_id": "...",
  "query": "...",
  "timestamp": "..."
}
```

---

## ğŸ§® **ML Model Details**

### **Embedding Model:**
```python
# sentence-transformers/all-MiniLM-L6-v2
# - Dimensions: 384
# - Speed: Fast (~0.1s for batch of 100)
# - Quality: Good for product search
# - Size: 80MB

# Alternative: all-mpnet-base-v2 (768-dim, better quality)
```

### **Recommendation Algorithm:**
```python
# Collaborative Filtering (User-based)
similarity(user_A, user_B) = cosine(purchases_A, purchases_B)
recommendations = top_products_of_similar_users(user_A)

# Content-Based (Product similarity)
similarity(product_A, product_B) = cosine(embedding_A, embedding_B)
recommendations = most_similar_products(product_A)

# Hybrid
final_score = Î± * collaborative_score + Î² * content_score + Î³ * popularity
```

---

## âš™ï¸ **Configuration**

### **Environment Variables:**
```bash
# Database
DATABASE_URL=postgresql://user:pass@host:port/ai_search_db

# Redis
REDIS_URL=redis://localhost:6379/4

# JWT
JWT_SECRET_KEY=same-as-auth-service

# ML Models
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
MODEL_CACHE_DIR=./ml_models/

# Vector Search
VECTOR_DIMENSIONS=384
SIMILARITY_THRESHOLD=0.7

# External Services
PRODUCT_SERVICE_URL=http://localhost:8002
ANALYTICS_SERVICE_URL=http://localhost:8005

# Performance
MAX_SEARCH_RESULTS=50
ENABLE_CACHE=true
CACHE_TTL=300
```

---

## ğŸ“Š **Performance Targets**

| Metric | Target | Notes |
|--------|--------|-------|
| Search Latency | < 200ms | P95 response time |
| Embedding Generation | < 100ms | Per product |
| Vector Search | < 50ms | pgvector query |
| Recommendations | < 300ms | Top 10 products |
| Cache Hit Rate | > 80% | For popular queries |
| Concurrent Users | 1000+ | With caching |

---

## ğŸ§ª **Testing Strategy**

### **Unit Tests:**
- Embedding generation
- Vector similarity calculations
- Query preprocessing
- Recommendation algorithms

### **Integration Tests:**
- Search API endpoints
- Product Service integration
- Database queries
- Cache behavior

### **Performance Tests:**
- Load testing (1000+ concurrent users)
- Embedding batch processing
- Vector search performance
- Cache effectiveness

### **ML Tests:**
- Embedding quality (relevance)
- Recommendation accuracy
- A/B testing framework

---

## ğŸš¨ **Key Challenges & Solutions**

### **Challenge 1: Cold Start Problem**
**Problem:** New users/products have no data for recommendations  
**Solution:**
- Use content-based recommendations initially
- Recommend trending/popular products
- Gradual transition to personalized as data accumulates

### **Challenge 2: Embedding Drift**
**Problem:** Product data changes, embeddings become stale  
**Solution:**
- Background job to regenerate embeddings nightly
- Track last_updated timestamp
- Prioritize high-traffic products

### **Challenge 3: Search Performance**
**Problem:** Vector search can be slow for large datasets  
**Solution:**
- Use pgvector with IVFFLAT index
- Implement aggressive caching
- Pre-compute for popular queries
- Consider Pinecone for scale

### **Challenge 4: Relevance**
**Problem:** AI search may return irrelevant results  
**Solution:**
- Hybrid search (vector + keyword)
- Apply business rules (stock, active status)
- Track click-through rates
- Use search analytics to improve

---

## ğŸ“ˆ **Scaling Considerations**

### **Data Growth:**
- **100K products:** pgvector sufficient
- **1M+ products:** Consider Pinecone/Milvus
- **Sharding:** By category or geography

### **Traffic Growth:**
- **< 10 req/s:** Single instance
- **< 100 req/s:** Add caching + 2-3 instances
- **> 100 req/s:** Load balancer + Redis cluster

### **ML Model Updates:**
- Rolling deployment for model updates
- A/B testing new models
- Gradual rollout (10% â†’ 50% â†’ 100%)

---

## ğŸ“š **Dependencies**

```txt
# Core
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.0.0
pydantic-settings>=2.0.0

# Database
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.9
pgvector>=0.2.3

# ML/AI
sentence-transformers>=2.2.2
scikit-learn>=1.3.0
numpy>=1.24.0
pandas>=2.0.0
torch>=2.0.0             # For transformers

# Utilities
httpx>=0.25.0            # Product Service client
redis>=5.0.0             # Caching
python-dotenv>=1.0.0
```

---

## ğŸ¯ **Success Metrics**

| Metric | Target | Measurement |
|--------|--------|-------------|
| Search Relevance | > 85% | Click-through rate |
| Recommendation CTR | > 10% | Clicks / Impressions |
| Search Coverage | > 95% | Queries with results |
| User Engagement | +30% | Time on site |
| Conversion Rate | +15% | Search â†’ Purchase |
| Response Time | < 200ms | P95 latency |

---

## ğŸ”„ **Integration with Frontend**

### **Search Component:**
```typescript
// Frontend calls
POST /api/search/semantic
{
  "query": "wireless headphones",
  "user_id": "...",        // Optional for personalization
  "filters": {
    "category": "electronics",
    "min_price": 50
  },
  "limit": 20
}

// Response
{
  "results": [
    {
      "product_id": "...",
      "score": 0.95,
      "product": { /* full product data */ }
    }
  ],
  "suggestions": ["bluetooth headphones", "noise cancelling"],
  "total": 150
}
```

---

## ğŸ“ **Next Steps After Planning**

1. **Review & Approve** this plan
2. **Set up infrastructure** (PostgreSQL + pgvector)
3. **Download ML models** (sentence-transformers)
4. **Implement phase by phase**
5. **Test with real product data**
6. **Deploy & monitor**

---

**This service will provide intelligent, AI-powered search and recommendations to significantly improve user experience and conversion rates!** ğŸ¤–ğŸ”

---

**Estimated Development Time:** 6 weeks  
**Team Size:** 1-2 developers + 1 ML engineer (optional)  
**Priority:** Medium (enhance existing platform)
